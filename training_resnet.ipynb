{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliasantoro99/AI-REPO/blob/main/training_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4gdYobEbDUJ",
        "outputId": "66747179-7b50-4c28-dbaf-1e86156fbdf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Scarico il dataset da Roboflow...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "✅ Dataset salvato in: /content/RoboAnimeProject-2\n",
            "📊 Numero classi: 6\n",
            "🖥️  Esecuzione su: cuda\n",
            "📂 Carico immagini di training e validazione...\n",
            "✅ Immagini train: 700 | valid: 200\n",
            "🧠 Creo modello ResNet18 pre-addestrato...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Inizio training...\n",
            "\n",
            "\n",
            "🔁 Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 1.5114 | Acc: 0.3771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.4020 | Acc: 0.3750\n",
            "💾 Model migliorato! Salvato.\n",
            "\n",
            "🔁 Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.8094 | Acc: 0.7457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.2882 | Acc: 0.5000\n",
            "💾 Model migliorato! Salvato.\n",
            "\n",
            "🔁 Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.4090 | Acc: 0.9100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.3399 | Acc: 0.5150\n",
            "⏳ Nessun miglioramento (1/5)\n",
            "\n",
            "🔁 Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.2226 | Acc: 0.9571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.3484 | Acc: 0.5050\n",
            "⏳ Nessun miglioramento (2/5)\n",
            "\n",
            "🔁 Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.1298 | Acc: 0.9786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.3558 | Acc: 0.5350\n",
            "⏳ Nessun miglioramento (3/5)\n",
            "\n",
            "🔁 Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.0666 | Acc: 0.9914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.4010 | Acc: 0.5100\n",
            "⏳ Nessun miglioramento (4/5)\n",
            "\n",
            "🔁 Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Train Loss: 0.0536 | Acc: 0.9929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Val Loss: 1.4807 | Acc: 0.4950\n",
            "⏳ Nessun miglioramento (5/5)\n",
            "🛑 Early stopping attivato!\n",
            "\n",
            "✅ Training completato!\n",
            "📌 Miglior modello salvato in: best_model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==================== STEP 1: IMPORT LIBRERIE ==========================\n",
        "from roboflow import Roboflow                    # Per connettersi a Roboflow e scaricare dataset\n",
        "import torch                                     # Libreria PyTorch base\n",
        "import torch.nn as nn                            # Per definire layer e architetture delle reti\n",
        "import torch.optim as optim                      # Per ottimizzatori come Adam\n",
        "from torchvision import datasets, transforms, models  # Per dataset, trasformazioni immagini e modelli predefiniti\n",
        "from torch.utils.data import DataLoader          # Per gestire i batch di dati durante il training\n",
        "from tqdm import tqdm                            # Per visualizzare una barra di avanzamento\n",
        "import os                                        # Per lavorare con file system (percorso file, ecc.)\n",
        "\n",
        "# ==================== STEP 2: SCARICAMENTO DATASET ROBOFLOW ==========================\n",
        "print(\"⬇️ Scarico il dataset da Roboflow...\")\n",
        "\n",
        "# Inizializza client Roboflow usando la tua API key (qui pubblica)\n",
        "rf = Roboflow(api_key=\"GAQ2cbOSPLavcNiilrPr\")\n",
        "\n",
        "# Seleziona il workspace e progetto da cui scaricare il dataset\n",
        "project = rf.workspace(\"roboanime\").project(\"roboanimeproject\")\n",
        "\n",
        "# Scarica la versione 1 del dataset nel formato \"folder\" (organizzato in sottocartelle)\n",
        "dataset = project.version(2).download(\"folder\")\n",
        "\n",
        "# Memorizza il percorso locale del dataset scaricato\n",
        "data_dir = dataset.location\n",
        "print(f\"✅ Dataset salvato in: {data_dir}\")\n",
        "\n",
        "# ==================== STEP 3: PARAMETRI DI CONFIGURAZIONE ==========================\n",
        "batch_size = 32              # Quante immagini usare in ogni batch di training\n",
        "max_epochs = 20              # Numero massimo di epoche (ripetizioni su tutto il dataset)\n",
        "patience = 5                 # Numero di epoche da aspettare senza miglioramento prima dello stop\n",
        "lr = 1e-4                    # Learning rate: quanto velocemente il modello impara\n",
        "best_model_path = \"best_model.pt\"  # Dove salvare il miglior modello\n",
        "\n",
        "# Conta il numero di classi leggendo il numero di sottocartelle nella directory \"train\"\n",
        "num_classes = len(os.listdir(os.path.join(data_dir, \"train\")))\n",
        "\n",
        "# Se c'è una GPU disponibile, usa quella, altrimenti usa la CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"📊 Numero classi: {num_classes}\")\n",
        "print(f\"🖥️  Esecuzione su: {device}\")\n",
        "\n",
        "# ==================== STEP 4: DEFINIZIONE TRASFORMAZIONI IMMAGINI ==========================\n",
        "# Le immagini devono essere tutte ridimensionate a 224x224 (formato richiesto da ResNet18)\n",
        "# Normalize serve a riportare i valori RGB all'intervallo [-1, 1] come atteso dai modelli pre-addestrati su ImageNet\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),           # Resize immagine\n",
        "        transforms.RandomHorizontalFlip(),       # Flip orizzontale casuale per data augmentation\n",
        "        transforms.ToTensor(),                   # Converti immagine in tensore\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])  # Normalizza secondo le statistiche di ImageNet\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# ==================== STEP 5: CARICAMENTO DATI E DATASET ==========================\n",
        "print(\"📂 Carico immagini di training e validazione...\")\n",
        "\n",
        "# Crea dataset da cartelle locali, applicando le trasformazioni\n",
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=data_transforms['train'])\n",
        "val_dataset   = datasets.ImageFolder(os.path.join(data_dir, \"valid\"), transform=data_transforms['val'])\n",
        "\n",
        "# Crea dataloader per leggere i dati a batch (in modo più efficiente)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # shuffle solo per train\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "print(f\"✅ Immagini train: {len(train_dataset)} | valid: {len(val_dataset)}\")\n",
        "\n",
        "# ==================== STEP 6: COSTRUZIONE MODELLO RESNET18 ==========================\n",
        "print(\"🧠 Creo modello ResNet18 pre-addestrato...\")\n",
        "\n",
        "# Carica un modello ResNet18 pre-addestrato su ImageNet\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Sostituisci l’ultimo layer per adattarlo al numero delle classi del tuo dataset\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Sposta il modello su GPU (o CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# ==================== STEP 7: FUNZIONE DI PERDITA E OTTIMIZZATORE ==========================\n",
        "criterion = nn.CrossEntropyLoss()              # Funzione di loss per classificazione multi-classe\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)  # Ottimizzatore Adam\n",
        "\n",
        "# ==================== STEP 8: EARLY STOPPING SETUP ==========================\n",
        "best_val_loss = float('inf')   # Per tenere traccia della loss migliore vista finora\n",
        "epochs_no_improve = 0          # Conteggio di quante epoche senza miglioramento\n",
        "\n",
        "# ==================== STEP 9: CICLO DI TRAINING CON EARLY STOPPING ==========================\n",
        "print(\"🚀 Inizio training...\\n\")\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    print(f\"\\n🔁 Epoch {epoch}/{max_epochs}\")\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()  # Modalità training o evaluation\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Usa il dataloader corrispondente alla fase\n",
        "        dataloader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        # Loop su tutti i batch della fase corrente\n",
        "        for inputs, labels in tqdm(dataloader, desc=phase, leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Sposta dati su GPU/CPU\n",
        "            optimizer.zero_grad()  # Azzeramento dei gradienti\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):  # Solo nel training fai il backward\n",
        "                outputs = model(inputs)            # Predizione\n",
        "                _, preds = torch.max(outputs, 1)   # Classe predetta\n",
        "                loss = criterion(outputs, labels)  # Calcolo della perdita\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()                # Backpropagation\n",
        "                    optimizer.step()               # Aggiorna pesi\n",
        "\n",
        "            # Accumula risultati per calcolare accuracy e loss medi\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "        # Calcolo di loss e accuracy medi su tutta l'epoca\n",
        "        epoch_loss = running_loss / total_samples\n",
        "        epoch_acc = running_corrects.double() / total_samples\n",
        "        print(f\"📊 {phase.capitalize()} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        # ---------------- EARLY STOPPING SULLA VALIDAZIONE ----------------\n",
        "        if phase == 'val':\n",
        "            if epoch_loss < best_val_loss:\n",
        "                best_val_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), best_model_path)  # Salva modello migliore\n",
        "                print(\"💾 Model migliorato! Salvato.\")\n",
        "                epochs_no_improve = 0  # Reset del contatore\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                print(f\"⏳ Nessun miglioramento ({epochs_no_improve}/{patience})\")\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(\"🛑 Early stopping attivato!\")\n",
        "                    break  # Esce dal ciclo esterno\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        break\n",
        "\n",
        "# ==================== FINE TRAINING ==========================\n",
        "print(\"\\n✅ Training completato!\")\n",
        "print(f\"📌 Miglior modello salvato in: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgQCfEUmgCAf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOTvk3bnmuySQFhuXqUI+RX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}